{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91714,"databundleVersionId":11251744,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Rainfall Prediction with CatBoost and Optuna\n\nIn this notebook, we use CatBoost, a powerful gradient boosting algorithm, along with Optuna for hyperparameter tuning to predict rainfall based on weather data. We also apply feature engineering and feature selection to improve model performance.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries\nWe begin by importing all the necessary libraries, including CatBoost for modeling, Optuna for hyperparameter optimization, and standard Python libraries like pandas and numpy for data manipulation.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport optuna\nimport warnings\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score, roc_auc_score, roc_curve\n\nwarnings.filterwarnings('ignore')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the Dataset\nWe load the training and test datasets. The training set contains the target variable (rainfall) that we will predict, while the test set will be used to evaluate our final model.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('path/to/your/train.csv')\ntest = pd.read_csv('path/to/your/test.csv')\n\ny = train['rainfall']\nX = train.drop(['id', 'rainfall'], axis=1)\nX_test = test.drop(['id'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering\nFeature engineering is crucial for improving model performance. Here, we create new features based on the existing ones to capture additional information from the data, such as the difference between maximum and minimum temperatures, wind direction components, and other interactions between weather features.","metadata":{}},{"cell_type":"code","source":"def add_features(df):\n    df['temp_range'] = df['maxtemp'] - df['mintemp']\n    df['dewpoint_diff'] = df['temparature'] - df['dewpoint']\n    df['wind_x'] = df['windspeed'] * np.cos(np.radians(df['winddirection']))\n    df['wind_y'] = df['windspeed'] * np.sin(np.radians(df['winddirection']))\n    df['cloud_sun_ratio'] = df['cloud'] / (df['sunshine'] + 1)\n    df['sun_intensity'] = df['sunshine'] * df['temparature']\n    df['humidity_pressure'] = df['humidity'] * df['pressure']\n    df['humidity_temp_ratio'] = df['humidity'] / (df['temparature'] + 1)\n    return df\n\nX = add_features(X)\nX_test = add_features(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Selection with CatBoost\nWe use the CatBoost model to identify and select the most important features. This step helps in reducing the dimensionality of the dataset, which can improve both model training time and performance.","metadata":{}},{"cell_type":"code","source":"cat_feat_model = CatBoostClassifier(iterations=700, learning_rate=0.03, depth=6, random_seed=42, verbose=0)\ncat_feat_model.fit(X, y)\nimportances = pd.Series(cat_feat_model.get_feature_importance(Pool(X, label=y)), index=X.columns)\ntop_features = importances.sort_values(ascending=False).head(20).index.tolist()\n\nX_top = X[top_features]\nX_test_top = X_test[top_features]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameter Tuning with Optuna\nTo improve the modelâ€™s performance, we use Optuna for hyperparameter optimization. Optuna will automatically search for the best combination of hyperparameters for the CatBoost model, using cross-validation to evaluate performance.","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'iterations': 700,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'depth': trial.suggest_int('depth', 4, 10),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),        \n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n        'random_strength': trial.suggest_float('random_strength', 0.0, 10.0),\n        'border_count': trial.suggest_int('border_count', 32, 255),\n        'verbose': 0,\n        'random_seed': 42,\n        'loss_function': 'Logloss',\n        'eval_metric': 'AUC'\n    }\n\n    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    aucs = []\n\n    for train_idx, val_idx in kf.split(X_top, y):\n        X_tr, X_val = X_top.iloc[train_idx], X_top.iloc[val_idx]\n        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        model = CatBoostClassifier(**params)\n        model.fit(X_tr, y_tr)\n        preds = model.predict_proba(X_val)[:, 1]\n        aucs.append(roc_auc_score(y_val, preds))\n\n    return np.mean(aucs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Final Model Training\nUsing the best hyperparameters found by Optuna, we train the final CatBoost model on the full training dataset and predict the rainfall on the test dataset.","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=30)\n\nbest_params = study.best_params\nbest_params.update({\n    'iterations': 700,\n    'verbose': 0,\n    'random_seed': 42\n})\n\nfinal_model = CatBoostClassifier(**best_params)\nfinal_model.fit(X_top, y)\nfinal_probs = final_model.predict_proba(X_test_top)[:, 1]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\nIn this notebook, we successfully built a CatBoost model with Optuna hyperparameter tuning and feature engineering to predict rainfall. ","metadata":{}},{"cell_type":"markdown","source":"### If you found this notebook useful:\nIf you have any feedback or suggestions to improve the code, feel free to open an **issue** or **pull request**. Contributions are welcome!\n","metadata":{}}]}